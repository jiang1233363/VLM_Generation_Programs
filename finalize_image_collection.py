#!/usr/bin/env python3
"""
å®Œæˆå›¾ç‰‡æ”¶é›† - åˆ†ææ‰€æœ‰å›¾ç‰‡è´¨é‡å¹¶é€‰æ‹©æœ€å¥½çš„100å¼ 
"""

import cv2
import numpy as np
import json
import os
from pathlib import Path
from PIL import Image
import hashlib
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

class ImageCollectionFinalizer:
    """å›¾ç‰‡æ”¶é›†æœ€ç»ˆå¤„ç†å™¨"""
    
    def __init__(self, base_dir: str = "/home/jgy/visual_boundary_dataset"):
        self.base_dir = Path(base_dir)
        self.downloaded_dir = self.base_dir / "downloaded_images"
        self.selected_dir = self.base_dir / "selected_images"
        self.metadata_dir = self.base_dir / "metadata"
        
        # åˆ›å»ºæœ€ç»ˆé€‰æ‹©ç›®å½•
        self.selected_dir.mkdir(exist_ok=True)
        self.metadata_dir.mkdir(exist_ok=True)
    
    def get_image_hash(self, image_path: str) -> str:
        """è®¡ç®—å›¾ç‰‡å“ˆå¸Œå€¼"""
        try:
            with open(image_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except:
            return ""
    
    def analyze_image_quality(self, image_path: Path) -> dict:
        """è¯¦ç»†åˆ†æå•å¼ å›¾ç‰‡è´¨é‡"""
        try:
            # åŸºæœ¬æ£€æŸ¥
            if not image_path.exists() or os.path.getsize(image_path) < 3000:
                return None
            
            # åŠ è½½å›¾ç‰‡
            image = cv2.imread(str(image_path))
            if image is None:
                return None
            
            # è·å–PILå›¾ç‰‡ä¿¡æ¯
            with Image.open(image_path) as pil_img:
                pil_img.verify()
                
            with Image.open(image_path) as pil_img:
                width, height = pil_img.size
                format_name = pil_img.format
                mode = pil_img.mode
            
            # å°ºå¯¸è¿‡å°çš„è·³è¿‡
            if width < 200 or height < 200:
                return None
            
            # è½¬æ¢è‰²å½©ç©ºé—´
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # æ¸…æ™°åº¦ - æ‹‰æ™®æ‹‰æ–¯æ–¹å·®
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # äº®åº¦ - RGBå¹³å‡å€¼
            brightness = np.mean(rgb)
            
            # å¯¹æ¯”åº¦ - ç°åº¦æ ‡å‡†å·®
            contrast = gray.std()
            
            # é¢œè‰²ä¸°å¯Œåº¦ - è‰²ç›¸æ–¹å·®
            color_variance = hsv[:,:,0].std()
            
            # é¥±å’Œåº¦ - Sé€šé“å¹³å‡å€¼
            saturation = np.mean(hsv[:,:,1])
            
            # å™ªå£°ä¼°è®¡ - é«˜é¢‘æˆåˆ†
            noise_level = np.mean(np.abs(cv2.Laplacian(gray, cv2.CV_64F)))
            
            # è¾¹ç¼˜å¯†åº¦
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (width * height)
            
            # åŠ¨æ€èŒƒå›´
            dynamic_range = gray.max() - gray.min()
            
            # ç»¼åˆè´¨é‡è¯„åˆ†
            # æ¸…æ™°åº¦æƒé‡æœ€é«˜
            sharpness_score = min(sharpness / 800, 1.0) * 0.25
            
            # äº®åº¦é€‚ä¸­æœ€å¥½ (128å·¦å³)
            brightness_score = (1.0 - abs(brightness - 128) / 128) * 0.15
            
            # å¯¹æ¯”åº¦é€‚ä¸­
            contrast_score = min(contrast / 70, 1.0) * 0.20
            
            # é¢œè‰²ä¸°å¯Œåº¦
            color_score = min(color_variance / 50, 1.0) * 0.10
            
            # é¥±å’Œåº¦é€‚ä¸­
            saturation_score = min(saturation / 200, 1.0) * 0.10
            
            # å™ªå£°æƒ©ç½š
            noise_penalty = max(0, 1 - noise_level / 15) * 0.05
            
            # è¾¹ç¼˜ä¸°å¯Œåº¦
            edge_score = min(edge_density * 10, 1.0) * 0.10
            
            # åŠ¨æ€èŒƒå›´
            dynamic_score = min(dynamic_range / 200, 1.0) * 0.05
            
            quality_score = (sharpness_score + brightness_score + contrast_score + 
                           color_score + saturation_score + noise_penalty + 
                           edge_score + dynamic_score)
            
            return {
                'filename': image_path.name,
                'file_path': str(image_path),
                'width': width,
                'height': height,
                'resolution': width * height,
                'file_size': os.path.getsize(image_path),
                'format': format_name,
                'mode': mode,
                'sharpness': float(sharpness),
                'brightness': float(brightness),
                'contrast': float(contrast),
                'color_variance': float(color_variance),
                'saturation': float(saturation),
                'noise_level': float(noise_level),
                'edge_density': float(edge_density),
                'dynamic_range': int(dynamic_range),
                'quality_score': float(quality_score),
                'hash': self.get_image_hash(str(image_path))
            }
            
        except Exception as e:
            print(f"âŒ åˆ†æå¤±è´¥ {image_path.name}: {e}")
            return None
    
    def finalize_collection(self, target_count: int = 100):
        """å®Œæˆå›¾ç‰‡æ”¶é›†å’Œé€‰æ‹©"""
        print("ğŸ¯ å®Œæˆå›¾ç‰‡æ”¶é›†å’Œè´¨é‡åˆ†æ")
        print("=" * 50)
        
        # æ”¶é›†æ‰€æœ‰å›¾ç‰‡
        all_images = list(self.downloaded_dir.glob("*.jpg")) + list(self.downloaded_dir.glob("*.jpeg"))
        print(f"ğŸ“ å‘ç° {len(all_images)} å¼ å›¾ç‰‡")
        
        # åˆ†ææ¯å¼ å›¾ç‰‡è´¨é‡
        valid_analyses = []
        unique_hashes = set()
        
        print("ğŸ” å¼€å§‹è´¨é‡åˆ†æ...")
        for i, img_path in enumerate(all_images, 1):
            print(f"  åˆ†æ {i}/{len(all_images)}: {img_path.name}")
            
            analysis = self.analyze_image_quality(img_path)
            if analysis and analysis['hash'] not in unique_hashes:
                valid_analyses.append(analysis)
                unique_hashes.add(analysis['hash'])
                print(f"    âœ“ è´¨é‡åˆ†æ•°: {analysis['quality_score']:.3f}")
            else:
                print(f"    âŒ æ— æ•ˆæˆ–é‡å¤")
        
        print(f"\nğŸ“Š æœ‰æ•ˆå›¾ç‰‡: {len(valid_analyses)} å¼ ")
        
        # æŒ‰è´¨é‡åˆ†æ•°æ’åº
        valid_analyses.sort(key=lambda x: x['quality_score'], reverse=True)
        
        # é€‰æ‹©æœ€å¥½çš„Nå¼ 
        selected_count = min(target_count, len(valid_analyses))
        selected_images = valid_analyses[:selected_count]
        
        print(f"ğŸ† é€‰æ‹©æœ€ä½³ {selected_count} å¼ å›¾ç‰‡")
        
        # å¤åˆ¶é€‰ä¸­çš„å›¾ç‰‡åˆ°é€‰æ‹©ç›®å½•
        for i, analysis in enumerate(selected_images, 1):
            src_path = Path(analysis['file_path'])
            # ä½¿ç”¨ç»Ÿä¸€å‘½åæ ¼å¼
            if 'existing_face_' in src_path.name:
                category = 'face'
                dst_name = f"face_{i:03d}_{src_path.name.replace('existing_', '')}"
            elif 'existing_' in src_path.name and any(fruit in src_path.name for fruit in ['apple', 'banana', 'cherry', 'grape']):
                category = 'fruit'
                dst_name = f"fruit_{i:03d}_{src_path.name.replace('existing_', '')}"
            else:
                category = 'general'
                dst_name = f"general_{i:03d}_{src_path.name}"
            
            dst_path = self.selected_dir / dst_name
            
            try:
                import shutil
                shutil.copy2(src_path, dst_path)
                # æ›´æ–°è·¯å¾„ä¿¡æ¯
                analysis['selected_filename'] = dst_name
                analysis['selected_path'] = str(dst_path)
                analysis['category'] = category
                print(f"  âœ“ {dst_name} (è´¨é‡: {analysis['quality_score']:.3f})")
            except Exception as e:
                print(f"  âŒ å¤åˆ¶å¤±è´¥: {e}")
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        if selected_images:
            avg_quality = sum(img['quality_score'] for img in selected_images) / len(selected_images)
            total_size = sum(img['file_size'] for img in selected_images)
            
            # è´¨é‡åˆ†å¸ƒ
            quality_ranges = {
                'excellent': len([img for img in selected_images if img['quality_score'] >= 0.8]),
                'very_good': len([img for img in selected_images if 0.7 <= img['quality_score'] < 0.8]),
                'good': len([img for img in selected_images if 0.6 <= img['quality_score'] < 0.7]),
                'fair': len([img for img in selected_images if 0.5 <= img['quality_score'] < 0.6]),
                'poor': len([img for img in selected_images if img['quality_score'] < 0.5])
            }
            
            # åˆ†è¾¨ç‡åˆ†å¸ƒ
            resolutions = [img['resolution'] for img in selected_images]
            avg_resolution = sum(resolutions) / len(resolutions)
            
            # åˆ†ç±»ç»Ÿè®¡
            categories = {}
            for img in selected_images:
                cat = img.get('category', 'unknown')
                categories[cat] = categories.get(cat, 0) + 1
        else:
            avg_quality = 0
            total_size = 0
            quality_ranges = {}
            avg_resolution = 0
            categories = {}
        
        # ç”Ÿæˆæœ€ç»ˆå…ƒæ•°æ®
        final_metadata = {
            'dataset_info': {
                'name': 'Visual Boundary Dataset - Base Images',
                'description': 'ç”¨äºè§†è§‰è¾¹ç•Œæµ‹è¯•çš„é«˜è´¨é‡çœŸå®å›¾ç‰‡é›†åˆ',
                'total_candidates': len(all_images),
                'valid_images': len(valid_analyses),
                'selected_images': len(selected_images),
                'target_count': target_count,
                'collection_date': str(Path(__file__).stat().st_mtime),
                'avg_quality_score': float(avg_quality),
                'total_size_mb': total_size / (1024 * 1024),
                'avg_resolution': int(avg_resolution),
            },
            'quality_distribution': quality_ranges,
            'category_distribution': categories,
            'selected_images': selected_images
        }
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata_file = self.metadata_dir / "final_image_collection.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(final_metadata, f, indent=2, ensure_ascii=False)
        
        # æ‰“å°æ€»ç»“
        print(f"\nâœ… å›¾ç‰‡æ”¶é›†å®Œæˆ!")
        print(f"ğŸ“„ å…ƒæ•°æ®ä¿å­˜: {metadata_file}")
        print(f"ğŸ“‚ é€‰æ‹©å›¾ç‰‡ç›®å½•: {self.selected_dir}")
        print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   æ€»å€™é€‰å›¾ç‰‡: {len(all_images)} å¼ ")
        print(f"   æœ‰æ•ˆå›¾ç‰‡: {len(valid_analyses)} å¼ ")
        print(f"   æœ€ç»ˆé€‰æ‹©: {len(selected_images)} å¼ ")
        print(f"   å¹³å‡è´¨é‡åˆ†æ•°: {avg_quality:.3f}")
        print(f"   æ€»æ–‡ä»¶å¤§å°: {total_size / (1024 * 1024):.1f} MB")
        print(f"   å¹³å‡åˆ†è¾¨ç‡: {int(avg_resolution):,} åƒç´ ")
        
        print(f"\nğŸ¯ è´¨é‡åˆ†å¸ƒ:")
        for range_name, count in quality_ranges.items():
            print(f"   {range_name}: {count} å¼ ")
        
        print(f"\nğŸ“‚ åˆ†ç±»åˆ†å¸ƒ:")
        for category, count in categories.items():
            print(f"   {category}: {count} å¼ ")
        
        return selected_images

def main():
    finalizer = ImageCollectionFinalizer()
    finalizer.finalize_collection(100)

if __name__ == "__main__":
    main()