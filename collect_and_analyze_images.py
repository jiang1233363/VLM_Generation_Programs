#!/usr/bin/env python3
"""
å›¾ç‰‡æ”¶é›†å’Œè´¨é‡åˆ†æè„šæœ¬
æ”¶é›†ç°æœ‰å›¾ç‰‡å¹¶åˆ†æè´¨é‡æŒ‡æ ‡
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageStat
import json
import shutil
from pathlib import Path
from typing import Dict, List, Tuple
import requests
import time

class ImageQualityAnalyzer:
    """å›¾åƒè´¨é‡åˆ†æå™¨"""
    
    def __init__(self):
        self.quality_metrics = [
            'sharpness',
            'brightness', 
            'contrast',
            'color_variance',
            'resolution',
            'file_size'
        ]
    
    def analyze_image_quality(self, image_path: str) -> Dict:
        """åˆ†æå•å¼ å›¾åƒçš„è´¨é‡æŒ‡æ ‡"""
        try:
            # ä½¿ç”¨PILåŠ è½½å›¾åƒ
            pil_image = Image.open(image_path).convert('RGB')
            
            # ä½¿ç”¨OpenCVåŠ è½½å›¾åƒ
            cv_image = cv2.imread(image_path)
            if cv_image is None:
                return {"error": "æ— æ³•åŠ è½½å›¾åƒ"}
            
            cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
            
            # è®¡ç®—å„ç§è´¨é‡æŒ‡æ ‡
            metrics = {
                'filename': Path(image_path).name,
                'file_path': image_path,
                'width': pil_image.width,
                'height': pil_image.height,
                'resolution': pil_image.width * pil_image.height,
                'file_size': os.path.getsize(image_path),
                'sharpness': float(self.calculate_sharpness(cv_image)),
                'brightness': float(self.calculate_brightness(cv_image_rgb)),
                'contrast': float(self.calculate_contrast(cv_image)),
                'color_variance': float(self.calculate_color_variance(cv_image_rgb)),
                'saturation': float(self.calculate_saturation(cv_image_rgb)),
                'noise_level': float(self.estimate_noise_level(cv_image)),
                'quality_score': 0  # å°†åœ¨åé¢è®¡ç®—
            }
            
            # è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°
            metrics['quality_score'] = float(self.calculate_overall_quality(metrics))
            
            return metrics
            
        except Exception as e:
            return {"error": str(e), "filename": Path(image_path).name}
    
    def calculate_sharpness(self, image: np.ndarray) -> float:
        """è®¡ç®—å›¾åƒæ¸…æ™°åº¦ï¼ˆæ‹‰æ™®æ‹‰æ–¯ç®—å­æ–¹å·®ï¼‰"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        return laplacian.var()
    
    def calculate_brightness(self, image: np.ndarray) -> float:
        """è®¡ç®—å›¾åƒäº®åº¦"""
        return np.mean(image)
    
    def calculate_contrast(self, image: np.ndarray) -> float:
        """è®¡ç®—å›¾åƒå¯¹æ¯”åº¦ï¼ˆæ ‡å‡†å·®ï¼‰"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        return np.std(gray)
    
    def calculate_color_variance(self, image: np.ndarray) -> float:
        """è®¡ç®—é¢œè‰²æ–¹å·®"""
        return np.var(image.reshape(-1, 3), axis=0).mean()
    
    def calculate_saturation(self, image: np.ndarray) -> float:
        """è®¡ç®—é¥±å’Œåº¦"""
        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
        return np.mean(hsv[:, :, 1])
    
    def estimate_noise_level(self, image: np.ndarray) -> float:
        """ä¼°è®¡å™ªå£°æ°´å¹³"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ä½¿ç”¨é«˜æ–¯æ»¤æ³¢å™¨ä¼°è®¡å™ªå£°
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        noise = gray.astype(np.float32) - blur.astype(np.float32)
        return np.std(noise)
    
    def calculate_overall_quality(self, metrics: Dict) -> float:
        """è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°"""
        try:
            # æ ‡å‡†åŒ–å„ä¸ªæŒ‡æ ‡ï¼ˆ0-1èŒƒå›´ï¼‰
            sharpness_norm = min(metrics['sharpness'] / 1000, 1.0)  # æ¸…æ™°åº¦
            brightness_norm = 1.0 - abs(metrics['brightness'] - 127.5) / 127.5  # äº®åº¦é€‚ä¸­æ€§
            contrast_norm = min(metrics['contrast'] / 100, 1.0)  # å¯¹æ¯”åº¦
            resolution_norm = min(metrics['resolution'] / (1920*1080), 1.0)  # åˆ†è¾¨ç‡
            
            # å™ªå£°æƒ©ç½š
            noise_penalty = max(0, 1.0 - metrics['noise_level'] / 10)
            
            # åŠ æƒå¹³å‡
            quality_score = (
                sharpness_norm * 0.3 +
                brightness_norm * 0.2 +
                contrast_norm * 0.2 +
                resolution_norm * 0.15 +
                noise_penalty * 0.15
            )
            
            return quality_score
            
        except Exception:
            return 0.0


class ImageCollector:
    """å›¾ç‰‡æ”¶é›†å™¨"""
    
    def __init__(self, output_dir: str = "data/original"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.analyzer = ImageQualityAnalyzer()
        self.collected_images = []
        
    def collect_from_input_folder(self, input_base_path: str = "/home/jgy/Input") -> List[Dict]:
        """ä»Inputæ–‡ä»¶å¤¹æ”¶é›†å›¾ç‰‡"""
        print("ğŸ“ ä»Inputæ–‡ä»¶å¤¹æ”¶é›†å›¾ç‰‡...")
        
        input_path = Path(input_base_path)
        collected = []
        
        # æ”¶é›†æ°´æœå›¾ç‰‡
        fruits_dir = input_path / "Fruits"
        if fruits_dir.exists():
            print(f"  æ”¶é›†æ°´æœå›¾ç‰‡ä»: {fruits_dir}")
            for img_file in fruits_dir.glob("*"):
                if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
                    # å¤åˆ¶åˆ°è¾“å‡ºç›®å½•
                    dest_path = self.output_dir / f"fruit_{img_file.name}"
                    shutil.copy2(img_file, dest_path)
                    
                    # åˆ†æè´¨é‡
                    quality_metrics = self.analyzer.analyze_image_quality(str(dest_path))
                    if "error" not in quality_metrics:
                        quality_metrics['category'] = 'fruit'
                        quality_metrics['source'] = 'local_input'
                        collected.append(quality_metrics)
                        print(f"    âœ“ {img_file.name} (è´¨é‡åˆ†æ•°: {quality_metrics['quality_score']:.3f})")
        
        # æ”¶é›†äººè„¸å›¾ç‰‡
        faces_dir = input_path / "Output_faces_clean"
        if faces_dir.exists():
            print(f"  æ”¶é›†äººè„¸å›¾ç‰‡ä»: {faces_dir}")
            face_count = 0
            for img_file in faces_dir.glob("*"):
                if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
                    # åªæ”¶é›†éƒ¨åˆ†äººè„¸å›¾ç‰‡ï¼ˆé¿å…å¤ªå¤šé‡å¤ï¼‰
                    if face_count >= 20:  # é™åˆ¶äººè„¸å›¾ç‰‡æ•°é‡
                        break
                        
                    dest_path = self.output_dir / f"face_{face_count:03d}_{img_file.name}"
                    shutil.copy2(img_file, dest_path)
                    
                    quality_metrics = self.analyzer.analyze_image_quality(str(dest_path))
                    if "error" not in quality_metrics:
                        quality_metrics['category'] = 'face'
                        quality_metrics['source'] = 'local_input'
                        collected.append(quality_metrics)
                        face_count += 1
                        print(f"    âœ“ {img_file.name} (è´¨é‡åˆ†æ•°: {quality_metrics['quality_score']:.3f})")
        
        self.collected_images.extend(collected)
        print(f"  ğŸ“Š ä»Inputæ–‡ä»¶å¤¹æ”¶é›†äº† {len(collected)} å¼ å›¾ç‰‡")
        return collected
    
    def download_additional_images(self, target_total: int = 100) -> List[Dict]:
        """ä»ç½‘ç»œä¸‹è½½é¢å¤–çš„é«˜è´¨é‡å›¾ç‰‡"""
        current_count = len(self.collected_images)
        needed = target_total - current_count
        
        if needed <= 0:
            print(f"å·²æœ‰ {current_count} å¼ å›¾ç‰‡ï¼Œæ— éœ€ä¸‹è½½æ›´å¤š")
            return []
        
        print(f"ğŸ“¡ éœ€è¦ä¸‹è½½ {needed} å¼ é¢å¤–å›¾ç‰‡...")
        
        # å®šä¹‰è¦ä¸‹è½½çš„å›¾ç‰‡ç±»åˆ«å’Œå¯¹åº”çš„æœç´¢å…³é”®è¯
        categories = {
            'animals': ['cat', 'dog', 'elephant', 'tiger', 'lion', 'bird', 'fish'],
            'objects': ['car', 'chair', 'table', 'book', 'phone', 'computer', 'camera'],
            'nature': ['flower', 'tree', 'mountain', 'ocean', 'sunset', 'landscape'],
            'food': ['pizza', 'burger', 'salad', 'cake', 'coffee', 'wine'],
            'architecture': ['building', 'bridge', 'castle', 'church', 'tower']
        }
        
        downloaded = []
        
        # ä»å…è´¹å›¾ç‰‡APIä¸‹è½½
        downloaded.extend(self.download_from_unsplash(needed // 2))
        downloaded.extend(self.download_from_pixabay(needed - len(downloaded)))
        
        self.collected_images.extend(downloaded)
        return downloaded
    
    def download_from_unsplash(self, count: int) -> List[Dict]:
        """ä»Unsplashä¸‹è½½é«˜è´¨é‡å›¾ç‰‡"""
        print(f"  ä»Unsplashä¸‹è½½ {count} å¼ å›¾ç‰‡...")
        downloaded = []
        
        # Unsplashçš„éšæœºå›¾ç‰‡API
        keywords = ['nature', 'animal', 'object', 'food', 'architecture', 'landscape', 'portrait']
        
        for i in range(count):
            try:
                keyword = keywords[i % len(keywords)]
                # ä½¿ç”¨Unsplashçš„Source APIè·å–éšæœºé«˜è´¨é‡å›¾ç‰‡
                url = f"https://source.unsplash.com/800x600/?{keyword}"
                
                response = requests.get(url, timeout=30, stream=True)
                if response.status_code == 200:
                    filename = f"unsplash_{keyword}_{i+1:03d}.jpg"
                    filepath = self.output_dir / filename
                    
                    with open(filepath, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            f.write(chunk)
                    
                    # åˆ†æè´¨é‡
                    quality_metrics = self.analyzer.analyze_image_quality(str(filepath))
                    if "error" not in quality_metrics:
                        quality_metrics['category'] = keyword
                        quality_metrics['source'] = 'unsplash'
                        downloaded.append(quality_metrics)
                        print(f"    âœ“ {filename} (è´¨é‡åˆ†æ•°: {quality_metrics['quality_score']:.3f})")
                    else:
                        filepath.unlink()  # åˆ é™¤æ— æ•ˆæ–‡ä»¶
                
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                
            except Exception as e:
                print(f"    âœ— ä¸‹è½½å¤±è´¥: {e}")
                continue
        
        return downloaded
    
    def download_from_pixabay(self, count: int) -> List[Dict]:
        """ä»Pixabayä¸‹è½½å›¾ç‰‡ï¼ˆéœ€è¦API keyï¼Œè¿™é‡Œä½¿ç”¨ç¤ºä¾‹URLsï¼‰"""
        print(f"  å°è¯•ä»å…¶ä»–æºä¸‹è½½ {count} å¼ å›¾ç‰‡...")
        downloaded = []
        
        # ä½¿ç”¨ä¸€äº›ç¤ºä¾‹é«˜è´¨é‡å›¾ç‰‡URL
        example_urls = [
            "https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800&h=600&fit=crop",
            "https://images.unsplash.com/photo-1441986300917-64674bd600d8?w=800&h=600&fit=crop",
            "https://images.unsplash.com/photo-1500648767791-00dcc994a43e?w=800&h=600&fit=crop"
        ]
        
        for i in range(min(count, len(example_urls))):
            try:
                url = example_urls[i]
                response = requests.get(url, timeout=30, stream=True)
                
                if response.status_code == 200:
                    filename = f"web_download_{i+1:03d}.jpg"
                    filepath = self.output_dir / filename
                    
                    with open(filepath, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            f.write(chunk)
                    
                    quality_metrics = self.analyzer.analyze_image_quality(str(filepath))
                    if "error" not in quality_metrics:
                        quality_metrics['category'] = 'mixed'
                        quality_metrics['source'] = 'web'
                        downloaded.append(quality_metrics)
                        print(f"    âœ“ {filename} (è´¨é‡åˆ†æ•°: {quality_metrics['quality_score']:.3f})")
                    else:
                        filepath.unlink()
                
                time.sleep(1)
                
            except Exception as e:
                print(f"    âœ— ä¸‹è½½å¤±è´¥: {e}")
                continue
        
        return downloaded
    
    def select_best_images(self, target_count: int = 100) -> List[Dict]:
        """é€‰æ‹©è´¨é‡æœ€å¥½çš„å›¾ç‰‡"""
        print(f"ğŸ” ä» {len(self.collected_images)} å¼ å›¾ç‰‡ä¸­é€‰æ‹©æœ€å¥½çš„ {target_count} å¼ ...")
        
        # æŒ‰è´¨é‡åˆ†æ•°æ’åº
        valid_images = [img for img in self.collected_images if "error" not in img]
        sorted_images = sorted(valid_images, key=lambda x: x['quality_score'], reverse=True)
        
        # é€‰æ‹©å‰Nå¼ ï¼ŒåŒæ—¶ä¿è¯ç±»åˆ«å¤šæ ·æ€§
        selected = []
        category_counts = {}
        
        # é¦–å…ˆæŒ‰ç±»åˆ«åˆ†ç»„
        by_category = {}
        for img in sorted_images:
            category = img.get('category', 'unknown')
            if category not in by_category:
                by_category[category] = []
            by_category[category].append(img)
        
        # å‡åŒ€é€‰æ‹©å„ç±»åˆ«çš„å›¾ç‰‡
        categories = list(by_category.keys())
        per_category = target_count // len(categories)
        remaining = target_count % len(categories)
        
        for i, category in enumerate(categories):
            count_for_this_category = per_category + (1 if i < remaining else 0)
            selected.extend(by_category[category][:count_for_this_category])
        
        # å¦‚æœè¿˜ä¸å¤Ÿï¼Œä»å‰©ä½™å›¾ç‰‡ä¸­é€‰æ‹©è´¨é‡æœ€é«˜çš„
        if len(selected) < target_count:
            remaining_images = [img for img in sorted_images if img not in selected]
            selected.extend(remaining_images[:target_count - len(selected)])
        
        # é‡æ–°æ’åºå¹¶æˆªå–
        selected = sorted(selected, key=lambda x: x['quality_score'], reverse=True)[:target_count]
        
        print(f"âœ“ é€‰æ‹©äº† {len(selected)} å¼ æœ€é«˜è´¨é‡å›¾ç‰‡")
        print("ç±»åˆ«åˆ†å¸ƒ:")
        category_counts = {}
        for img in selected:
            category = img.get('category', 'unknown')
            category_counts[category] = category_counts.get(category, 0) + 1
        
        for category, count in category_counts.items():
            print(f"  {category}: {count} å¼ ")
        
        return selected
    
    def save_metadata(self, selected_images: List[Dict], output_file: str = "metadata/image_collection.json"):
        """ä¿å­˜å›¾ç‰‡æ”¶é›†çš„å…ƒæ•°æ®"""
        metadata_path = Path(output_file)
        metadata_path.parent.mkdir(parents=True, exist_ok=True)
        
        metadata = {
            "collection_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_collected": len(self.collected_images),
            "selected_count": len(selected_images),
            "quality_metrics_used": self.analyzer.quality_metrics,
            "selected_images": selected_images,
            "statistics": self.calculate_statistics(selected_images)
        }
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ å…ƒæ•°æ®ä¿å­˜åˆ°: {metadata_path}")
        return metadata
    
    def calculate_statistics(self, images: List[Dict]) -> Dict:
        """è®¡ç®—å›¾ç‰‡é›†åˆçš„ç»Ÿè®¡ä¿¡æ¯"""
        if not images:
            return {}
        
        quality_scores = [img['quality_score'] for img in images]
        resolutions = [img['resolution'] for img in images]
        file_sizes = [img['file_size'] for img in images]
        
        return {
            "quality_score": {
                "mean": float(np.mean(quality_scores)),
                "std": float(np.std(quality_scores)),
                "min": float(np.min(quality_scores)),
                "max": float(np.max(quality_scores))
            },
            "resolution": {
                "mean": float(np.mean(resolutions)),
                "std": float(np.std(resolutions)),
                "min": float(np.min(resolutions)),
                "max": float(np.max(resolutions))
            },
            "file_size": {
                "mean": float(np.mean(file_sizes)),
                "std": float(np.std(file_sizes)),
                "min": float(np.min(file_sizes)),
                "max": float(np.max(file_sizes))
            }
        }


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ è§†è§‰è¾¹ç•Œæ•°æ®é›†å›¾ç‰‡æ”¶é›†å™¨")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ”¶é›†å™¨
    collector = ImageCollector("data/original")
    
    # æ­¥éª¤1: æ”¶é›†ç°æœ‰å›¾ç‰‡
    print("\næ­¥éª¤1: æ”¶é›†ç°æœ‰å›¾ç‰‡")
    collector.collect_from_input_folder()
    
    # æ­¥éª¤2: ä¸‹è½½é¢å¤–å›¾ç‰‡
    print("\næ­¥éª¤2: ä¸‹è½½é¢å¤–å›¾ç‰‡")
    collector.download_additional_images(target_total=100)
    
    # æ­¥éª¤3: é€‰æ‹©æœ€å¥½çš„100å¼ 
    print("\næ­¥éª¤3: é€‰æ‹©æœ€é«˜è´¨é‡å›¾ç‰‡")
    selected_images = collector.select_best_images(100)
    
    # æ­¥éª¤4: ä¿å­˜å…ƒæ•°æ®
    print("\næ­¥éª¤4: ä¿å­˜å…ƒæ•°æ®")
    metadata = collector.save_metadata(selected_images)
    
    print(f"\nâœ… å›¾ç‰‡æ”¶é›†å®Œæˆ!")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»æ”¶é›†: {len(collector.collected_images)} å¼ ")
    print(f"  æœ€ç»ˆé€‰æ‹©: {len(selected_images)} å¼ ")
    print(f"  å¹³å‡è´¨é‡åˆ†æ•°: {metadata['statistics']['quality_score']['mean']:.3f}")


if __name__ == "__main__":
    main()