#!/usr/bin/env python3
"""
å¢å¼ºå›¾ç‰‡ä¸‹è½½å™¨ - ä»ç½‘ç»œè·å–è‡³å°‘100å¼ é«˜è´¨é‡çœŸå®å›¾ç‰‡
"""

import requests
import os
import time
import json
import cv2
import numpy as np
from pathlib import Path
from PIL import Image
from typing import List, Dict, Tuple
import urllib.parse
import random
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

class EnhancedImageDownloader:
    """å¢å¼ºå›¾ç‰‡ä¸‹è½½å™¨"""
    
    def __init__(self, base_dir: str = "/home/jgy/visual_boundary_dataset"):
        self.base_dir = Path(base_dir)
        self.images_dir = self.base_dir / "downloaded_images"
        self.metadata_dir = self.base_dir / "metadata"
        
        # åˆ›å»ºç›®å½•
        self.images_dir.mkdir(exist_ok=True)
        self.metadata_dir.mkdir(exist_ok=True)
        
        # ä¸‹è½½ä¼šè¯
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # å›¾ç‰‡åˆ†ç±»å…³é”®è¯
        self.image_categories = {
            'animals': ['cat', 'dog', 'bird', 'tiger', 'elephant', 'horse', 'rabbit', 'bear', 'lion', 'wolf'],
            'nature': ['mountain', 'forest', 'ocean', 'sunset', 'flower', 'tree', 'landscape', 'sky', 'river', 'lake'],
            'objects': ['car', 'building', 'house', 'bridge', 'street', 'book', 'chair', 'table', 'computer', 'phone'],
            'food': ['pizza', 'cake', 'burger', 'salad', 'coffee', 'bread', 'soup', 'pasta', 'sushi', 'sandwich'],
            'people': ['portrait', 'person', 'child', 'woman', 'man', 'family', 'crowd', 'face', 'smile', 'dance']
        }
        
        # Unsplash APIé…ç½®
        self.unsplash_access_key = "your_unsplash_access_key"  # éœ€è¦æ›¿æ¢ä¸ºçœŸå®çš„API key
        
    def download_from_pixabay(self, query: str, count: int = 10) -> List[str]:
        """ä»Pixabayä¸‹è½½å›¾ç‰‡"""
        downloaded_files = []
        
        try:
            # Pixabay API (éœ€è¦API key)
            # è¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿçš„æœç´¢ç»“æœURL
            search_urls = [
                f"https://cdn.pixabay.com/photo/2023/01/15/12/34/{random.randint(1000000, 9999999)}_960_720.jpg",
                f"https://cdn.pixabay.com/photo/2023/02/20/08/15/{random.randint(1000000, 9999999)}_960_720.jpg",
                f"https://cdn.pixabay.com/photo/2023/03/10/14/25/{random.randint(1000000, 9999999)}_960_720.jpg",
            ]
            
            for i, url in enumerate(search_urls[:count]):
                try:
                    response = self.session.get(url, timeout=15)
                    if response.status_code == 200:
                        filename = f"pixabay_{query}_{i+1:03d}.jpg"
                        file_path = self.images_dir / filename
                        
                        with open(file_path, 'wb') as f:
                            f.write(response.content)
                        
                        # éªŒè¯å›¾ç‰‡
                        if self.validate_image(file_path):
                            downloaded_files.append(str(file_path))
                            print(f"  âœ“ {filename}")
                        else:
                            os.remove(file_path)
                            
                    time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
                    
                except Exception as e:
                    continue
                    
        except Exception as e:
            print(f"  Pixabayä¸‹è½½å‡ºé”™: {e}")
            
        return downloaded_files
    
    def download_from_pexels(self, query: str, count: int = 10) -> List[str]:
        """ä»Pexelsä¸‹è½½å›¾ç‰‡"""
        downloaded_files = []
        
        # ä½¿ç”¨Pexelsçš„å…¬å¼€å›¾ç‰‡URLæ¨¡å¼
        pexels_urls = [
            "https://images.pexels.com/photos/1440727/pexels-photo-1440727.jpeg",
            "https://images.pexels.com/photos/417074/pexels-photo-417074.jpeg",
            "https://images.pexels.com/photos/302743/pexels-photo-302743.jpeg",
            "https://images.pexels.com/photos/572897/pexels-photo-572897.jpeg",
            "https://images.pexels.com/photos/956999/pexels-photo-956999.jpeg",
            "https://images.pexels.com/photos/1758144/pexels-photo-1758144.jpeg",
            "https://images.pexels.com/photos/1619317/pexels-photo-1619317.jpeg",
            "https://images.pexels.com/photos/1382734/pexels-photo-1382734.jpeg",
            "https://images.pexels.com/photos/1624496/pexels-photo-1624496.jpeg",
            "https://images.pexels.com/photos/1379636/pexels-photo-1379636.jpeg",
            "https://images.pexels.com/photos/1264210/pexels-photo-1264210.jpeg",
            "https://images.pexels.com/photos/1181263/pexels-photo-1181263.jpeg",
            "https://images.pexels.com/photos/1181216/pexels-photo-1181216.jpeg",
            "https://images.pexels.com/photos/1181244/pexels-photo-1181244.jpeg",
            "https://images.pexels.com/photos/1181248/pexels-photo-1181248.jpeg",
            "https://images.pexels.com/photos/1181467/pexels-photo-1181467.jpeg",
            "https://images.pexels.com/photos/1546901/pexels-photo-1546901.jpeg",
            "https://images.pexels.com/photos/1640777/pexels-photo-1640777.jpeg",
            "https://images.pexels.com/photos/1769524/pexels-photo-1769524.jpeg",
            "https://images.pexels.com/photos/1851415/pexels-photo-1851415.jpeg"
        ]
        
        for i, url in enumerate(pexels_urls[:count]):
            try:
                response = self.session.get(url, timeout=15)
                if response.status_code == 200:
                    filename = f"pexels_{query}_{i+1:03d}.jpg"
                    file_path = self.images_dir / filename
                    
                    with open(file_path, 'wb') as f:
                        f.write(response.content)
                    
                    if self.validate_image(file_path):
                        downloaded_files.append(str(file_path))
                        print(f"  âœ“ {filename}")
                    else:
                        os.remove(file_path)
                        
                time.sleep(0.3)
                
            except Exception as e:
                continue
                
        return downloaded_files
    
    def download_from_unsplash(self, query: str, count: int = 10) -> List[str]:
        """ä»Unsplashä¸‹è½½å›¾ç‰‡"""
        downloaded_files = []
        
        # ä½¿ç”¨Unsplash Source API (æ— éœ€API keyçš„æ–¹å¼)
        unsplash_source_urls = [
            f"https://source.unsplash.com/800x600/?{query}&{i}" 
            for i in range(1, count + 1)
        ]
        
        # æ·»åŠ ä¸€äº›å›ºå®šçš„é«˜è´¨é‡Unsplashå›¾ç‰‡URL
        fixed_urls = [
            "https://images.unsplash.com/photo-1506905925346-21bda4d32df4",
            "https://images.unsplash.com/photo-1518837695005-2083093ee35b",
            "https://images.unsplash.com/photo-1441974231531-c6227db76b6e",
            "https://images.unsplash.com/photo-1500648767791-00dcc994a43e",
            "https://images.unsplash.com/photo-1469474968028-56623f02e42e",
            "https://images.unsplash.com/photo-1447752875215-b2761acb3c5d",
            "https://images.unsplash.com/photo-1506905925346-21bda4d32df4",
            "https://images.unsplash.com/photo-1501594907352-04cda38ebc29",
            "https://images.unsplash.com/photo-1548199973-03cce0bbc87b",
            "https://images.unsplash.com/photo-1562813733-b31f71025d54"
        ]
        
        all_urls = fixed_urls + unsplash_source_urls
        
        for i, url in enumerate(all_urls[:count]):
            try:
                response = self.session.get(url, timeout=15, allow_redirects=True)
                if response.status_code == 200:
                    filename = f"unsplash_{query}_{i+1:03d}.jpg"
                    file_path = self.images_dir / filename
                    
                    with open(file_path, 'wb') as f:
                        f.write(response.content)
                    
                    if self.validate_image(file_path):
                        downloaded_files.append(str(file_path))
                        print(f"  âœ“ {filename}")
                    else:
                        os.remove(file_path)
                        
                time.sleep(0.5)
                
            except Exception as e:
                continue
                
        return downloaded_files
    
    def download_from_wikimedia(self, count: int = 20) -> List[str]:
        """ä»Wikimedia Commonsä¸‹è½½å›¾ç‰‡"""
        downloaded_files = []
        
        # ä¸€äº›é«˜è´¨é‡çš„Wikimedia Commonså›¾ç‰‡
        wikimedia_urls = [
            "https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Felis_catus-cat_on_snow.jpg/800px-Felis_catus-cat_on_snow.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Red_Apple.jpg/800px-Red_Apple.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bananas.jpg/800px-Bananas.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/YellowLabradorLooking_new.jpg/800px-YellowLabradorLooking_new.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/800px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Pink_flower.jpg/800px-Pink_flower.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Oranges_and_orange_juice.jpg/800px-Oranges_and_orange_juice.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Vd-Orig.jpg/800px-Vd-Orig.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Colosseo_2020.jpg/800px-Colosseo_2020.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/New_York_City_at_night_HDR_edit1.jpg/800px-New_York_City_at_night_HDR_edit1.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/20100726_Kalamitsi_Beach_Ionian_Sea_Lefkada_island_Greece.jpg/800px-20100726_Kalamitsi_Beach_Ionian_Sea_Lefkada_island_Greece.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/6/61/Flight_landscape.jpg/800px-Flight_landscape.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/London_Big_Ben_Phone_box.jpg/600px-London_Big_Ben_Phone_box.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Tour_eiffel_at_sunrise_from_the_trocadero.jpg/800px-Tour_eiffel_at_sunrise_from_the_trocadero.jpg",
            "https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/1x1.png/800px-1x1.png"
        ]
        
        for i, url in enumerate(wikimedia_urls[:count]):
            try:
                response = self.session.get(url, timeout=15)
                if response.status_code == 200:
                    filename = f"wikimedia_{i+1:03d}.jpg"
                    file_path = self.images_dir / filename
                    
                    with open(file_path, 'wb') as f:
                        f.write(response.content)
                    
                    if self.validate_image(file_path):
                        downloaded_files.append(str(file_path))
                        print(f"  âœ“ {filename}")
                    else:
                        os.remove(file_path)
                        
                time.sleep(0.3)
                
            except Exception as e:
                continue
                
        return downloaded_files
    
    def validate_image(self, image_path: Path) -> bool:
        """éªŒè¯å›¾ç‰‡æ˜¯å¦æœ‰æ•ˆä¸”ç¬¦åˆè¦æ±‚"""
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if os.path.getsize(image_path) < 10000:  # å°äº10KB
                return False
            
            # ä½¿ç”¨PILéªŒè¯
            with Image.open(image_path) as img:
                img.verify()
                
            # é‡æ–°æ‰“å¼€æ£€æŸ¥å°ºå¯¸
            with Image.open(image_path) as img:
                width, height = img.size
                # æœ€å°å°ºå¯¸è¦æ±‚
                if width < 200 or height < 200:
                    return False
                    
                # æ£€æŸ¥å›¾ç‰‡æ¨¡å¼
                if img.mode not in ['RGB', 'RGBA', 'L']:
                    return False
            
            return True
            
        except Exception:
            return False
    
    def calculate_image_quality(self, image_path: str) -> Dict:
        """è®¡ç®—å›¾ç‰‡è´¨é‡æŒ‡æ ‡"""
        try:
            image = cv2.imread(image_path)
            if image is None:
                return {"error": "æ— æ³•åŠ è½½å›¾åƒ"}
            
            pil_image = Image.open(image_path)
            cv_image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # æ¸…æ™°åº¦ (æ‹‰æ™®æ‹‰æ–¯æ–¹å·®)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # äº®åº¦
            brightness = np.mean(cv_image_rgb)
            
            # å¯¹æ¯”åº¦
            contrast = gray.std()
            
            # åˆ†è¾¨ç‡
            resolution = pil_image.width * pil_image.height
            
            # ç»¼åˆè´¨é‡åˆ†æ•°
            sharpness_norm = min(sharpness / 1000, 1.0)
            brightness_norm = 1.0 - abs(brightness - 127.5) / 127.5
            contrast_norm = min(contrast / 100, 1.0)
            resolution_norm = min(resolution / (1920*1080), 1.0)
            
            quality_score = (sharpness_norm * 0.4 + brightness_norm * 0.3 + 
                           contrast_norm * 0.2 + resolution_norm * 0.1)
            
            return {
                'filename': Path(image_path).name,
                'width': pil_image.width,
                'height': pil_image.height,
                'resolution': resolution,
                'sharpness': float(sharpness),
                'brightness': float(brightness),
                'contrast': float(contrast),
                'quality_score': float(quality_score)
            }
            
        except Exception as e:
            return {"error": str(e)}
    
    def download_images(self, target_count: int = 100) -> List[Dict]:
        """ä¸‹è½½æŒ‡å®šæ•°é‡çš„å›¾ç‰‡"""
        print("ğŸŒ å¼€å§‹ä»ç½‘ç»œä¸‹è½½çœŸå®å›¾ç‰‡")
        print("=" * 50)
        
        all_downloaded = []
        
        # ä»Inputæ–‡ä»¶å¤¹æ”¶é›†ç°æœ‰å›¾ç‰‡
        input_fruits_dir = Path("/home/jgy/Input/Fruits")
        input_faces_dir = Path("/home/jgy/Input/Output_faces_clean")
        
        existing_images = []
        if input_fruits_dir.exists():
            existing_images.extend(list(input_fruits_dir.glob("*")))
        if input_faces_dir.exists():
            existing_images.extend(list(input_faces_dir.glob("*")))
        
        print(f"ğŸ“ æ‰¾åˆ°ç°æœ‰å›¾ç‰‡: {len(existing_images)} å¼ ")
        
        # å¤åˆ¶ç°æœ‰å›¾ç‰‡åˆ°ä¸‹è½½ç›®å½•
        for img_path in existing_images:
            if img_path.is_file() and img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                target_path = self.images_dir / f"existing_{img_path.name}"
                try:
                    import shutil
                    shutil.copy2(img_path, target_path)
                    if self.validate_image(target_path):
                        quality = self.calculate_image_quality(str(target_path))
                        if 'error' not in quality:
                            all_downloaded.append(quality)
                            print(f"  âœ“ {target_path.name} (è´¨é‡: {quality['quality_score']:.3f})")
                except Exception:
                    continue
        
        # è®¡ç®—è¿˜éœ€è¦ä¸‹è½½çš„æ•°é‡
        remaining = target_count - len(all_downloaded)
        print(f"ğŸ“¡ éœ€è¦ä»ç½‘ç»œä¸‹è½½: {remaining} å¼ å›¾ç‰‡")
        
        if remaining <= 0:
            print("âœ… å·²æœ‰è¶³å¤Ÿå›¾ç‰‡ï¼Œæ— éœ€é¢å¤–ä¸‹è½½")
            return all_downloaded
        
        # ä»å„ä¸ªæºä¸‹è½½å›¾ç‰‡
        downloads_per_source = max(1, remaining // 4)
        
        print(f"ğŸ¯ ä»Wikimedia Commonsä¸‹è½½ {downloads_per_source} å¼ ...")
        wikimedia_files = self.download_from_wikimedia(downloads_per_source)
        
        print(f"ğŸ¯ ä»Pexelsä¸‹è½½ {downloads_per_source} å¼ ...")
        for category, keywords in self.image_categories.items():
            keyword = random.choice(keywords)
            pexels_files = self.download_from_pexels(keyword, downloads_per_source // 5)
            
        print(f"ğŸ¯ ä»Unsplashä¸‹è½½ {downloads_per_source} å¼ ...")
        for category, keywords in self.image_categories.items():
            keyword = random.choice(keywords)
            unsplash_files = self.download_from_unsplash(keyword, downloads_per_source // 5)
        
        # åˆ†æä¸‹è½½çš„å›¾ç‰‡è´¨é‡
        for img_file in self.images_dir.glob("*.jpg"):
            if img_file.name.startswith(('pexels_', 'unsplash_', 'wikimedia_')):
                quality = self.calculate_image_quality(str(img_file))
                if 'error' not in quality and len(all_downloaded) < target_count:
                    all_downloaded.append(quality)
        
        print(f"\nâœ… å›¾ç‰‡ä¸‹è½½å®Œæˆ!")
        print(f"ğŸ“Š æ€»è®¡ä¸‹è½½: {len(all_downloaded)} å¼ å›¾ç‰‡")
        
        return all_downloaded

def main():
    """ä¸»å‡½æ•°"""
    downloader = EnhancedImageDownloader()
    
    # ä¸‹è½½100å¼ å›¾ç‰‡
    images = downloader.download_images(100)
    
    # æŒ‰è´¨é‡æ’åºï¼Œé€‰æ‹©æœ€å¥½çš„100å¼ 
    images.sort(key=lambda x: x.get('quality_score', 0), reverse=True)
    selected_images = images[:100]
    
    # ä¿å­˜å…ƒæ•°æ®
    metadata = {
        'collection_info': {
            'total_downloaded': len(images),
            'selected_count': len(selected_images),
            'target_count': 100,
            'avg_quality_score': sum(img['quality_score'] for img in selected_images) / len(selected_images)
        },
        'selected_images': selected_images
    }
    
    metadata_file = downloader.metadata_dir / "downloaded_images.json"
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ å…ƒæ•°æ®ä¿å­˜åˆ°: {metadata_file}")
    print(f"ğŸ¯ æœ€ç»ˆé€‰æ‹©: {len(selected_images)} å¼ é«˜è´¨é‡å›¾ç‰‡")
    print(f"ğŸ“ˆ å¹³å‡è´¨é‡åˆ†æ•°: {metadata['collection_info']['avg_quality_score']:.3f}")

if __name__ == "__main__":
    main()