#!/usr/bin/env python3
"""
è‰²ç›²æµ‹è¯•æ•°æ®é›†ç”Ÿæˆè„šæœ¬
æ•´åˆä¸‹è½½ã€æ¨¡æ‹Ÿå’Œæ¢¯åº¦ç”Ÿæˆçš„å®Œæ•´æµç¨‹
"""

import os
import sys
import json
import time
from pathlib import Path
from PIL import Image
import numpy as np

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥å…¶ä»–æ¨¡å—
sys.path.append(str(Path(__file__).parent))

from download_ishihara_plates import IshiharaDownloader
from colorblind_simulation import ColorBlindnessSimulator, ColorBlindnessMetrics

class ColorBlindnessDatasetGenerator:
    def __init__(self, base_dir=".."):
        """åˆå§‹åŒ–æ•°æ®é›†ç”Ÿæˆå™¨"""
        self.base_dir = Path(base_dir)
        self.raw_dir = self.base_dir / "data" / "raw"
        self.processed_dir = self.base_dir / "data" / "processed"
        self.gradients_dir = self.base_dir / "data" / "gradients"
        self.metadata_dir = self.base_dir / "metadata"
        
        # åˆ›å»ºç›®å½•
        for dir_path in [self.raw_dir, self.processed_dir, self.gradients_dir, self.metadata_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        self.downloader = IshiharaDownloader(str(self.raw_dir))
        self.simulator = ColorBlindnessSimulator()
        self.metrics = ColorBlindnessMetrics()
        
        # è‰²ç›²ç±»å‹é…ç½®
        self.colorblind_types = ['protanopia', 'deuteranopia', 'tritanopia']
        self.gradient_steps = 100
    
    def step1_download_base_images(self):
        """æ­¥éª¤1: ä¸‹è½½åŸºç¡€å›¾åƒ"""
        print("=== æ­¥éª¤1: ä¸‹è½½åŸºç¡€å›¾åƒ ===")
        self.downloader.run()
        
        # æ£€æŸ¥ä¸‹è½½ç»“æœ
        image_files = list(self.raw_dir.glob("*.png")) + list(self.raw_dir.glob("*.jpg"))
        print(f"è·å¾— {len(image_files)} å¼ åŸºç¡€å›¾åƒ")
        return len(image_files) >= 100  # å¿…é¡»è¦æœ‰100å¼ çœŸå®ç½‘ç»œå›¾åƒ
    
    def step2_generate_gradients(self):
        """æ­¥éª¤2: ä¸ºæ¯å¼ åŸºç¡€å›¾åƒç”Ÿæˆè‰²ç›²æ¨¡æ‹Ÿæ¢¯åº¦"""
        print("=== æ­¥éª¤2: ç”Ÿæˆè‰²ç›²æ¨¡æ‹Ÿæ¢¯åº¦ ===")
        
        # è·å–æ‰€æœ‰åŸºç¡€å›¾åƒ
        image_extensions = {'.png', '.jpg', '.jpeg', '.bmp'}
        base_images = []
        
        for ext in image_extensions:
            base_images.extend(self.raw_dir.glob(f"*{ext}"))
        
        if not base_images:
            print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°åŸºç¡€å›¾åƒ")
            return False
        
        print(f"æ‰¾åˆ° {len(base_images)} å¼ åŸºç¡€å›¾åƒ")
        
        total_generated = 0
        dataset_metadata = {
            "generation_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_base_images": len(base_images),
            "colorblind_types": self.colorblind_types,
            "gradient_steps": self.gradient_steps,
            "images": []
        }
        
        for i, image_file in enumerate(base_images):
            print(f"\nå¤„ç†å›¾åƒ {i+1}/{len(base_images)}: {image_file.name}")
            
            try:
                # åŠ è½½å¹¶éªŒè¯å›¾åƒ
                image = Image.open(image_file).convert('RGB')
                print(f"  å›¾åƒå°ºå¯¸: {image.size}")
                
                # ä¸ºæ¯ç§è‰²ç›²ç±»å‹ç”Ÿæˆæ¢¯åº¦
                image_metadata = {
                    "base_image": image_file.name,
                    "base_image_path": str(image_file),
                    "image_size": image.size,
                    "colorblind_variants": {}
                }
                
                for colorblind_type in self.colorblind_types:
                    print(f"  ç”Ÿæˆ {colorblind_type} æ¢¯åº¦...")
                    
                    # åˆ›å»ºè¾“å‡ºç›®å½•
                    type_output_dir = self.gradients_dir / image_file.stem / colorblind_type
                    type_output_dir.mkdir(parents=True, exist_ok=True)
                    
                    # ç”Ÿæˆæ¢¯åº¦åºåˆ—
                    generated_files = []
                    contrast_analyses = []
                    
                    for step in range(self.gradient_steps + 1):
                        severity = step / self.gradient_steps
                        
                        # åº”ç”¨è‰²ç›²æ¨¡æ‹Ÿ
                        sim_func = getattr(self.simulator, f'simulate_{colorblind_type}')
                        simulated_image = sim_func(image, severity)
                        
                        # ä¿å­˜å›¾åƒ
                        filename = f"step_{step:03d}_severity_{severity:.2f}.png"
                        filepath = type_output_dir / filename
                        simulated_image.save(filepath)
                        generated_files.append(str(filepath))
                        
                        # æ¯10æ­¥åˆ†æä¸€æ¬¡å¯¹æ¯”åº¦
                        if step % 10 == 0:
                            contrast_analysis = self.simulator.analyze_color_contrast(
                                image, colorblind_type, severity
                            )
                            contrast_analysis["step"] = step
                            contrast_analysis["filepath"] = str(filepath)
                            contrast_analyses.append(contrast_analysis)
                    
                    # è®¡ç®—å¯è§æ€§é˜ˆå€¼
                    try:
                        visibility_threshold = self.metrics.calculate_visibility_threshold(
                            image, colorblind_type
                        )
                    except Exception as e:
                        print(f"    è­¦å‘Š: æ— æ³•è®¡ç®—å¯è§æ€§é˜ˆå€¼: {e}")
                        visibility_threshold = None
                    
                    variant_metadata = {
                        "colorblind_type": colorblind_type,
                        "generated_files": generated_files,
                        "num_gradients": len(generated_files),
                        "contrast_analyses": contrast_analyses,
                        "visibility_threshold": visibility_threshold,
                        "output_directory": str(type_output_dir)
                    }
                    
                    image_metadata["colorblind_variants"][colorblind_type] = variant_metadata
                    total_generated += len(generated_files)
                    
                    print(f"    âœ“ ç”Ÿæˆäº† {len(generated_files)} ä¸ªæ¢¯åº¦æ–‡ä»¶")
                    if visibility_threshold is not None:
                        print(f"    å¯è§æ€§é˜ˆå€¼: {visibility_threshold:.2f}")
                
                dataset_metadata["images"].append(image_metadata)
                
            except Exception as e:
                print(f"  âœ— å¤„ç†å¤±è´¥: {e}")
                continue
        
        # ä¿å­˜æ•°æ®é›†å…ƒæ•°æ®
        metadata_file = self.metadata_dir / "complete_dataset.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_metadata, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡
        stats = self.generate_dataset_statistics(dataset_metadata)
        stats_file = self.metadata_dir / "dataset_statistics.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"\n=== æ¢¯åº¦ç”Ÿæˆå®Œæˆ ===")
        print(f"æ€»å…±ç”Ÿæˆ: {total_generated} å¼ å›¾åƒ")
        print(f"å…ƒæ•°æ®ä¿å­˜åˆ°: {metadata_file}")
        print(f"ç»Ÿè®¡ä¿¡æ¯ä¿å­˜åˆ°: {stats_file}")
        
        return total_generated > 0
    
    def generate_dataset_statistics(self, metadata):
        """ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "dataset_overview": {
                "total_base_images": metadata["total_base_images"],
                "total_gradient_images": 0,
                "colorblind_types": metadata["colorblind_types"],
                "gradient_steps": metadata["gradient_steps"]
            },
            "images_per_type": {},
            "visibility_thresholds": {},
            "contrast_analysis_summary": {}
        }
        
        # ç»Ÿè®¡æ¯ç§è‰²ç›²ç±»å‹çš„å›¾åƒæ•°é‡
        for cb_type in self.colorblind_types:
            stats["images_per_type"][cb_type] = 0
            stats["visibility_thresholds"][cb_type] = []
            stats["contrast_analysis_summary"][cb_type] = {
                "avg_color_difference": [],
                "avg_contrast_change": []
            }
        
        # éå†æ‰€æœ‰å›¾åƒè®¡ç®—ç»Ÿè®¡
        for image_meta in metadata["images"]:
            for cb_type, variant_meta in image_meta["colorblind_variants"].items():
                # å›¾åƒæ•°é‡
                stats["images_per_type"][cb_type] += variant_meta["num_gradients"]
                stats["dataset_overview"]["total_gradient_images"] += variant_meta["num_gradients"]
                
                # å¯è§æ€§é˜ˆå€¼
                if variant_meta["visibility_threshold"] is not None:
                    stats["visibility_thresholds"][cb_type].append(
                        variant_meta["visibility_threshold"]
                    )
                
                # å¯¹æ¯”åº¦åˆ†æ
                for analysis in variant_meta["contrast_analyses"]:
                    stats["contrast_analysis_summary"][cb_type]["avg_color_difference"].append(
                        analysis["color_difference"]
                    )
                    stats["contrast_analysis_summary"][cb_type]["avg_contrast_change"].append(
                        analysis["contrast_change"]
                    )
        
        # è®¡ç®—å¹³å‡å€¼
        for cb_type in self.colorblind_types:
            if stats["visibility_thresholds"][cb_type]:
                stats["visibility_thresholds"][cb_type] = {
                    "mean": np.mean(stats["visibility_thresholds"][cb_type]),
                    "std": np.std(stats["visibility_thresholds"][cb_type]),
                    "min": np.min(stats["visibility_thresholds"][cb_type]),
                    "max": np.max(stats["visibility_thresholds"][cb_type])
                }
            
            summary = stats["contrast_analysis_summary"][cb_type]
            if summary["avg_color_difference"]:
                summary["avg_color_difference"] = {
                    "mean": np.mean(summary["avg_color_difference"]),
                    "std": np.std(summary["avg_color_difference"])
                }
            if summary["avg_contrast_change"]:
                summary["avg_contrast_change"] = {
                    "mean": np.mean(summary["avg_contrast_change"]),
                    "std": np.std(summary["avg_contrast_change"])
                }
        
        return stats
    
    def step3_create_test_cases(self):
        """æ­¥éª¤3: åˆ›å»ºæµ‹è¯•ç”¨ä¾‹æè¿°"""
        print("=== æ­¥éª¤3: åˆ›å»ºæµ‹è¯•ç”¨ä¾‹æè¿° ===")
        
        test_cases = []
        
        # è¯»å–æ•°æ®é›†å…ƒæ•°æ®
        metadata_file = self.metadata_dir / "complete_dataset.json"
        if not metadata_file.exists():
            print("é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›†å…ƒæ•°æ®æ–‡ä»¶")
            return False
        
        with open(metadata_file, 'r', encoding='utf-8') as f:
            dataset_metadata = json.load(f)
        
        # ä¸ºæ¯ä¸ªåŸºç¡€å›¾åƒåˆ›å»ºæµ‹è¯•ç”¨ä¾‹
        for image_meta in dataset_metadata["images"]:
            base_image = image_meta["base_image"]
            
            # ç¡®å®šæœŸæœ›çš„ç­”æ¡ˆï¼ˆåŸºäºæ–‡ä»¶åæˆ–å…ƒæ•°æ®ï¼‰
            expected_answer = self.extract_expected_answer(base_image)
            
            for cb_type, variant_meta in image_meta["colorblind_variants"].items():
                # åˆ›å»ºæµ‹è¯•åºåˆ—
                test_sequence = {
                    "test_id": f"{Path(base_image).stem}_{cb_type}",
                    "base_image": base_image,
                    "colorblind_type": cb_type,
                    "expected_answer": expected_answer,
                    "test_description": f"æµ‹è¯•æ¨¡å‹åœ¨{cb_type}æ¨¡æ‹Ÿä¸‹è¯†åˆ«{expected_answer}çš„èƒ½åŠ›",
                    "gradient_files": variant_meta["generated_files"],
                    "num_gradients": variant_meta["num_gradients"],
                    "visibility_threshold": variant_meta["visibility_threshold"],
                    "test_questions": []
                }
                
                # ä¸ºå…³é”®æ¢¯åº¦ç‚¹åˆ›å»ºæµ‹è¯•é—®é¢˜
                key_steps = [0, 25, 50, 75, 100]  # å…³é”®æµ‹è¯•ç‚¹
                for step in key_steps:
                    if step < len(variant_meta["generated_files"]):
                        severity = step / 100.0
                        test_question = {
                            "step": step,
                            "severity": severity,
                            "image_path": variant_meta["generated_files"][step],
                            "question": f"è¿™å¼ å›¾ä¸­æ˜¾ç¤ºçš„æ˜¯ä»€ä¹ˆæ•°å­—æˆ–ç¬¦å·ï¼Ÿ",
                            "expected_answer": expected_answer,
                            "difficulty_level": self.assess_difficulty_level(severity, variant_meta["visibility_threshold"])
                        }
                        test_sequence["test_questions"].append(test_question)
                
                test_cases.append(test_sequence)
        
        # ä¿å­˜æµ‹è¯•ç”¨ä¾‹
        test_cases_file = self.metadata_dir / "test_cases.json"
        with open(test_cases_file, 'w', encoding='utf-8') as f:
            json.dump({
                "total_test_sequences": len(test_cases),
                "creation_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "test_sequences": test_cases
            }, f, indent=2, ensure_ascii=False)
        
        print(f"åˆ›å»ºäº† {len(test_cases)} ä¸ªæµ‹è¯•åºåˆ—")
        print(f"æµ‹è¯•ç”¨ä¾‹ä¿å­˜åˆ°: {test_cases_file}")
        return True
    
    def extract_expected_answer(self, filename):
        """ä»æ–‡ä»¶åæå–æœŸæœ›ç­”æ¡ˆ"""
        filename_lower = filename.lower()
        
        # æ£€æŸ¥æ–‡ä»¶åä¸­çš„æ•°å­—
        import re
        numbers = re.findall(r'\d+', filename)
        if numbers:
            return numbers[0]
        
        # æ£€æŸ¥æ–‡ä»¶åä¸­çš„å…³é”®è¯
        if 'circle' in filename_lower:
            return 'circle'
        elif 'square' in filename_lower:
            return 'square'
        elif 'triangle' in filename_lower:
            return 'triangle'
        
        return 'unknown'
    
    def assess_difficulty_level(self, severity, visibility_threshold):
        """è¯„ä¼°æµ‹è¯•éš¾åº¦çº§åˆ«"""
        if visibility_threshold is None:
            return "unknown"
        
        if severity < visibility_threshold * 0.5:
            return "easy"
        elif severity < visibility_threshold:
            return "medium"
        elif severity < visibility_threshold * 1.5:
            return "hard"
        else:
            return "very_hard"
    
    def generate_readme(self):
        """ç”Ÿæˆæ•°æ®é›†è¯´æ˜æ–‡æ¡£"""
        readme_content = f"""# è‰²ç›²æµ‹è¯•æ•°æ®é›†

## æ¦‚è¿°
è¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°AIæ¨¡å‹è‰²å½©è§†è§‰èƒ½åŠ›çš„ç»¼åˆè‰²ç›²æµ‹è¯•æ•°æ®é›†ã€‚æ•°æ®é›†åŒ…å«çŸ³åŸæ°è‰²ç›²æµ‹è¯•å›¾çš„å¤šä¸ªå˜ä½“ï¼Œæ¨¡æ‹Ÿä¸åŒç±»å‹å’Œä¸¥é‡ç¨‹åº¦çš„è‰²ç›²çŠ¶å†µã€‚

## æ•°æ®é›†ç»“æ„
```
colorblindness/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # åŸå§‹åŸºç¡€å›¾åƒ
â”‚   â”œâ”€â”€ processed/             # å¤„ç†åçš„å›¾åƒ
â”‚   â””â”€â”€ gradients/             # è‰²ç›²æ¨¡æ‹Ÿæ¢¯åº¦å›¾åƒ
â”‚       â””â”€â”€ [image_name]/
â”‚           â”œâ”€â”€ protanopia/    # çº¢è‰²ç›²æ¨¡æ‹Ÿ (101å¼ å›¾åƒ, 0%-100%ä¸¥é‡ç¨‹åº¦)
â”‚           â”œâ”€â”€ deuteranopia/  # ç»¿è‰²ç›²æ¨¡æ‹Ÿ (101å¼ å›¾åƒ, 0%-100%ä¸¥é‡ç¨‹åº¦)  
â”‚           â””â”€â”€ tritanopia/    # è“è‰²ç›²æ¨¡æ‹Ÿ (101å¼ å›¾åƒ, 0%-100%ä¸¥é‡ç¨‹åº¦)
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ complete_dataset.json     # å®Œæ•´æ•°æ®é›†å…ƒæ•°æ®
â”‚   â”œâ”€â”€ dataset_statistics.json   # æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
â”‚   â””â”€â”€ test_cases.json          # æµ‹è¯•ç”¨ä¾‹å®šä¹‰
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_ishihara_plates.py    # å›¾åƒä¸‹è½½è„šæœ¬
â”‚   â”œâ”€â”€ colorblind_simulation.py       # è‰²ç›²æ¨¡æ‹Ÿç®—æ³•
â”‚   â””â”€â”€ generate_dataset.py            # æ•°æ®é›†ç”Ÿæˆä¸»è„šæœ¬
â””â”€â”€ docs/
    â””â”€â”€ README.md                       # æœ¬æ–‡æ¡£
```

## è‰²ç›²ç±»å‹
- **Protanopia (çº¢è‰²ç›²)**: æ— æ³•æ„ŸçŸ¥çº¢å…‰
- **Deuteranopia (ç»¿è‰²ç›²)**: æ— æ³•æ„ŸçŸ¥ç»¿å…‰  
- **Tritanopia (è“è‰²ç›²)**: æ— æ³•æ„ŸçŸ¥è“å…‰

## æ¢¯åº¦ç”Ÿæˆ
æ¯ä¸ªåŸºç¡€å›¾åƒéƒ½ä¼šç”Ÿæˆ101ä¸ªä¸åŒä¸¥é‡ç¨‹åº¦çš„è‰²ç›²æ¨¡æ‹Ÿç‰ˆæœ¬ï¼š
- æ­¥éª¤ 0: æ­£å¸¸è§†åŠ› (0% è‰²ç›²æ¨¡æ‹Ÿ)
- æ­¥éª¤ 1-99: æ¸è¿›è‰²ç›²æ¨¡æ‹Ÿ (1%-99% ä¸¥é‡ç¨‹åº¦)
- æ­¥éª¤ 100: å®Œå…¨è‰²ç›²æ¨¡æ‹Ÿ (100% ä¸¥é‡ç¨‹åº¦)

## ä½¿ç”¨æ–¹æ³•
1. è¿è¡Œ `python generate_dataset.py` ç”Ÿæˆå®Œæ•´æ•°æ®é›†
2. æŸ¥çœ‹ `metadata/test_cases.json` äº†è§£æµ‹è¯•ç”¨ä¾‹
3. ä½¿ç”¨ `metadata/dataset_statistics.json` äº†è§£æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯

## è¯„æµ‹æŒ‡æ ‡
- **å¯è§æ€§é˜ˆå€¼**: ç›®æ ‡å˜å¾—ä¸å¯è§çš„è‰²ç›²ä¸¥é‡ç¨‹åº¦
- **é¢œè‰²å¯¹æ¯”åº¦å˜åŒ–**: æ¨¡æ‹Ÿå‰åçš„é¢œè‰²å¯¹æ¯”åº¦å·®å¼‚
- **è¯†åˆ«å‡†ç¡®ç‡**: æ¨¡å‹åœ¨ä¸åŒä¸¥é‡ç¨‹åº¦ä¸‹çš„è¯†åˆ«å‡†ç¡®ç‡

## æ•°æ®é›†ç‰¹ç‚¹
- é«˜è´¨é‡çš„çŸ³åŸæ°è‰²ç›²æµ‹è¯•å›¾
- ç²¾ç¡®çš„è‰²ç›²æ¨¡æ‹Ÿç®—æ³•
- æ¸è¿›å¼æµ‹è¯•éš¾åº¦
- è¯¦ç»†çš„å…ƒæ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯
- å¤šç§è‰²ç›²ç±»å‹æ”¯æŒ

ç”Ÿæˆæ—¶é—´: {time.strftime("%Y-%m-%d %H:%M:%S")}
"""
        
        docs_dir = self.base_dir / "docs"
        docs_dir.mkdir(exist_ok=True)
        
        readme_file = docs_dir / "README.md"
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        print(f"READMEæ–‡æ¡£ä¿å­˜åˆ°: {readme_file}")
    
    def run_complete_generation(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®é›†ç”Ÿæˆæµç¨‹"""
        print("=== è‰²ç›²æµ‹è¯•æ•°æ®é›†ç”Ÿæˆå™¨ ===")
        print(f"å·¥ä½œç›®å½•: {self.base_dir.absolute()}")
        
        start_time = time.time()
        
        try:
            # æ­¥éª¤1: ä¸‹è½½åŸºç¡€å›¾åƒ
            if not self.step1_download_base_images():
                print("é”™è¯¯: åŸºç¡€å›¾åƒä¸‹è½½å¤±è´¥")
                return False
            
            # æ­¥éª¤2: ç”Ÿæˆæ¢¯åº¦
            if not self.step2_generate_gradients():
                print("é”™è¯¯: æ¢¯åº¦ç”Ÿæˆå¤±è´¥")
                return False
            
            # æ­¥éª¤3: åˆ›å»ºæµ‹è¯•ç”¨ä¾‹
            if not self.step3_create_test_cases():
                print("é”™è¯¯: æµ‹è¯•ç”¨ä¾‹åˆ›å»ºå¤±è´¥")
                return False
            
            # ç”Ÿæˆæ–‡æ¡£
            self.generate_readme()
            
            end_time = time.time()
            duration = end_time - start_time
            
            print(f"\n=== æ•°æ®é›†ç”Ÿæˆå®Œæˆ ===")
            print(f"æ€»è€—æ—¶: {duration:.2f} ç§’")
            print(f"æ•°æ®é›†ä½ç½®: {self.base_dir.absolute()}")
            
            # æœ€ç»ˆç»Ÿè®¡
            self.print_final_statistics()
            
            return True
            
        except Exception as e:
            print(f"æ•°æ®é›†ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats_file = self.metadata_dir / "dataset_statistics.json"
            if stats_file.exists():
                with open(stats_file, 'r', encoding='utf-8') as f:
                    stats = json.load(f)
                
                overview = stats["dataset_overview"]
                print(f"\næ•°æ®é›†ç»Ÿè®¡:")
                print(f"- åŸºç¡€å›¾åƒ: {overview['total_base_images']} å¼ ")
                print(f"- æ¢¯åº¦å›¾åƒ: {overview['total_gradient_images']} å¼ ")
                print(f"- è‰²ç›²ç±»å‹: {', '.join(overview['colorblind_types'])}")
                print(f"- æ¢¯åº¦æ­¥æ•°: {overview['gradient_steps']}")
                
                print(f"\nå„ç±»å‹å›¾åƒæ•°é‡:")
                for cb_type, count in stats["images_per_type"].items():
                    print(f"- {cb_type}: {count} å¼ ")
                    
        except Exception as e:
            print(f"æ— æ³•æ‰“å°ç»Ÿè®¡ä¿¡æ¯: {e}")


if __name__ == "__main__":
    # åˆ›å»ºç”Ÿæˆå™¨å¹¶è¿è¡Œ
    generator = ColorBlindnessDatasetGenerator()
    success = generator.run_complete_generation()
    
    if success:
        print("\nğŸ‰ æ•°æ®é›†ç”ŸæˆæˆåŠŸ!")
    else:
        print("\nâŒ æ•°æ®é›†ç”Ÿæˆå¤±è´¥!")
        sys.exit(1)